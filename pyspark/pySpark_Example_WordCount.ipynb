{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Simple Example : WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create SparkContext and SparkSession Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext('local', 'WordCount App')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.Builder().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Unstructured CSV file with SpackContext objext 'sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.textFile('input/python.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Lists allow us to hold items of heterogeneous types. In this article, we will learn how to create a list in Python; access the list items; find the number of items in the list, how to add an item to list; how to remove an item from the list; loop through list items; sorting a list, reversing a list; and many more transformation and aggregation actions on Python Lists']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data with RDD MapReduce functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5),\n",
       " ('the', 4),\n",
       " ('how', 3),\n",
       " ('a', 3),\n",
       " ('list', 3),\n",
       " ('list;', 3),\n",
       " ('Python', 2),\n",
       " ('Lists', 2),\n",
       " ('items', 2),\n",
       " ('of', 2)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.flatMap(lambda x: x.split(' '))\\\n",
    "    .map(lambda x: (x,1))\\\n",
    "    .reduceByKey(lambda a, b: a+b)\\\n",
    "    .sortBy(lambda kv: kv[1], False)\\\n",
    "    .collect()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Python Lists allow us to hold items of heterogeneous types. In this article, we will learn how to create a list in Python; access the list items; find the number of items in the list, how to add an item to list; how to remove an item from the list; loop through list items; sorting a list, reversing a list; and many more transformation and aggregation actions on Python Lists']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 5), ('the', 4), ('how', 3), ('a', 3), ('list', 3)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = rdd1.flatMap(lambda x: x.split(' '))\n",
    "rdd3 = rdd2.map(lambda x: (x, 1))\n",
    "rdd4 = rdd3.reduceByKey(lambda a, b: a+b)\n",
    "rdd5 = rdd4.sortBy(lambda kv: kv[1], False)\n",
    "rdd5.collect()[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Stuctured CSV file with SparkSession object 'spark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(path='input/traffic_sim.txt', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+---------------+-----+\n",
      "|dispatching_base_number|date    |active_vehicles|trips|\n",
      "+-----------------------+--------+---------------+-----+\n",
      "|B02512                 |1/1/2015|190            |1132 |\n",
      "|B02765                 |1/1/2015|225            |1765 |\n",
      "|B02764                 |1/1/2015|3427           |29421|\n",
      "|B02682                 |1/1/2015|945            |7679 |\n",
      "|B02617                 |1/1/2015|1228           |9537 |\n",
      "|B02598                 |1/1/2015|870            |6903 |\n",
      "|B02598                 |1/2/2015|785            |4768 |\n",
      "|B02617                 |1/2/2015|1137           |7065 |\n",
      "|B02512                 |1/2/2015|175            |875  |\n",
      "|B02682                 |1/2/2015|890            |5506 |\n",
      "+-----------------------+--------+---------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data with DataFrame functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dispatching_base_number', 'date', 'active_vehicles', 'trips']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+---------------+-----+-------------------+\n",
      "|dispatching_base_number|    date|active_vehicles|trips|          timestamp|\n",
      "+-----------------------+--------+---------------+-----+-------------------+\n",
      "|                 B02512|1/1/2015|            190| 1132|2015-01-01 00:00:00|\n",
      "|                 B02765|1/1/2015|            225| 1765|2015-01-01 00:00:00|\n",
      "|                 B02764|1/1/2015|           3427|29421|2015-01-01 00:00:00|\n",
      "|                 B02682|1/1/2015|            945| 7679|2015-01-01 00:00:00|\n",
      "|                 B02617|1/1/2015|           1228| 9537|2015-01-01 00:00:00|\n",
      "+-----------------------+--------+---------------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_ts = df1.withColumn(\"timestamp\", F.to_timestamp(df1.date, \"M/d/yyyy\"))\n",
    "df2_ts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+\n",
      "|dispatching_base_number|    date|active_vehicles|trips|          timestamp|year|month|dayofmonth|weekofyear|\n",
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+\n",
      "|                 B02598|2/1/2015|            961| 9499|2015-02-01 00:00:00|2015|    2|         1|         5|\n",
      "|                 B02764|2/1/2015|           3740|37468|2015-02-01 00:00:00|2015|    2|         1|         5|\n",
      "|                 B02682|2/1/2015|           1214|12436|2015-02-01 00:00:00|2015|    2|         1|         5|\n",
      "|                 B02512|2/1/2015|            193| 1377|2015-02-01 00:00:00|2015|    2|         1|         5|\n",
      "|                 B02765|2/1/2015|            289| 2672|2015-02-01 00:00:00|2015|    2|         1|         5|\n",
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3_ts_y_m_d = df2_ts.withColumn('year', F.year('timestamp'))\\\n",
    "                      .withColumn('month', F.month('timestamp'))\\\n",
    "                      .withColumn('dayofmonth', F.dayofmonth('timestamp'))\\\n",
    "                      .withColumn('weekofyear', F.weekofyear('timestamp'))\\\n",
    "                      .sort(F.desc('month'))\n",
    "df3_ts_y_m_d.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How many distinc year is recorder in the traffic data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|year|\n",
      "+----+\n",
      "|2015|\n",
      "+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3_ts_y_m_d.select('year').distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which month see the most trips in 2015?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "354"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_ts_y_m_d.select('month').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'961'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_ts_y_m_d.collect()[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df4_ts_y_m_d_int = df3_ts_y_m_d.withColumn('numtrips', df3_ts_y_m_d.trips.cast(IntegerType()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+--------+\n",
      "|dispatching_base_number|    date|active_vehicles|trips|          timestamp|year|month|dayofmonth|weekofyear|numtrips|\n",
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+--------+\n",
      "|                 B02598|2/1/2015|            961| 9499|2015-02-01 00:00:00|2015|    2|         1|         5|    9499|\n",
      "|                 B02764|2/1/2015|           3740|37468|2015-02-01 00:00:00|2015|    2|         1|         5|   37468|\n",
      "|                 B02682|2/1/2015|           1214|12436|2015-02-01 00:00:00|2015|    2|         1|         5|   12436|\n",
      "|                 B02512|2/1/2015|            193| 1377|2015-02-01 00:00:00|2015|    2|         1|         5|    1377|\n",
      "|                 B02765|2/1/2015|            289| 2672|2015-02-01 00:00:00|2015|    2|         1|         5|    2672|\n",
      "+-----------------------+--------+---------------+-----+-------------------+----+-----+----------+----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4_ts_y_m_d_int.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|month|sum(numtrips)|\n",
      "+-----+-------------+\n",
      "|    2|      2221581|\n",
      "|    1|      1908649|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4_ts_y_m_d_int.select('month', 'numtrips').groupBy('month').sum('numtrips').sort(F.desc('sum(numtrips)')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which day see the most trips in February?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|dayofmonth|sum(numtrips)|\n",
      "+----------+-------------+\n",
      "|        20|       100915|\n",
      "|        14|       100345|\n",
      "|        21|        98380|\n",
      "|        13|        98024|\n",
      "|        15|        89401|\n",
      "|        27|        88806|\n",
      "|        19|        88757|\n",
      "|        28|        88181|\n",
      "|         6|        85940|\n",
      "|        26|        83568|\n",
      "|        12|        83234|\n",
      "|         7|        81157|\n",
      "|         5|        80913|\n",
      "|        24|        79115|\n",
      "|         1|        76910|\n",
      "|        25|        74691|\n",
      "|        17|        73051|\n",
      "|        11|        72470|\n",
      "|        18|        72243|\n",
      "|        16|        72098|\n",
      "|        23|        71217|\n",
      "|         3|        70188|\n",
      "|         2|        68980|\n",
      "|         4|        66835|\n",
      "|        22|        66440|\n",
      "|        10|        64766|\n",
      "|         8|        63000|\n",
      "|         9|        61956|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df5=df4_ts_y_m_d_int.select('dayofmonth', 'numtrips')\\\n",
    "        .where(df4_ts_y_m_d_int.month == 2)\\\n",
    "        .groupBy('dayofmonth')\\\n",
    "        .sum('numtrips')\\\n",
    "        .sort(F.desc('sum(numtrips)'))\n",
    "df5.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dayofmonth', 'sum(numtrips)']"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df5.withColumnRenamed('sum(numtrips)', 'monthly_trips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|dayofmonth|monthly_trips|\n",
      "+----------+-------------+\n",
      "|        20|       100915|\n",
      "|        14|       100345|\n",
      "|        21|        98380|\n",
      "|        13|        98024|\n",
      "|        15|        89401|\n",
      "|        27|        88806|\n",
      "|        19|        88757|\n",
      "|        28|        88181|\n",
      "|         6|        85940|\n",
      "|        26|        83568|\n",
      "|        12|        83234|\n",
      "|         7|        81157|\n",
      "|         5|        80913|\n",
      "|        24|        79115|\n",
      "|         1|        76910|\n",
      "|        25|        74691|\n",
      "|        17|        73051|\n",
      "|        11|        72470|\n",
      "|        18|        72243|\n",
      "|        16|        72098|\n",
      "+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df6.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
