{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "conf=SparkConf().setMaster(\"local\").setAppName(\"myApp\")\n",
    "sc=SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|        Call Type|  count|\n",
      "+-----------------+-------+\n",
      "| Medical Incident|3411696|\n",
      "|   Structure Fire| 659644|\n",
      "|           Alarms| 565194|\n",
      "|Traffic Collision| 215006|\n",
      "|            Other|  82489|\n",
      "+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a schema \n",
    "fireschema = StructType([StructField('Call Number', IntegerType(), True),\n",
    "                     StructField('Unit ID', StringType(), True),\n",
    "                     StructField('Incident Number', IntegerType(), True),\n",
    "                     StructField('Call Type', StringType(), True),                  \n",
    "                     StructField('Call Date', StringType(), True),       \n",
    "                     StructField('Watch Date', StringType(), True),       \n",
    "                     StructField('Received DtTm', StringType(), True),       \n",
    "                     StructField('Entry DtTm', StringType(), True),       \n",
    "                     StructField('Dispatch DtTm', StringType(), True),       \n",
    "                     StructField('Response DtTm', StringType(), True),       \n",
    "                     StructField('On Scene DtTm', StringType(), True),       \n",
    "                     StructField('Transport DtTm', StringType(), True),                  \n",
    "                     StructField('Hospital DtTm', StringType(), True),       \n",
    "                     StructField('Call Final Disposition', StringType(), True),       \n",
    "                     StructField('Available DtTm', StringType(), True),       \n",
    "                     StructField('Address', StringType(), True),       \n",
    "                     StructField('City', StringType(), True),       \n",
    "                     StructField('Zipcode of Incident', IntegerType(), True),       \n",
    "                     StructField('Battalion', StringType(), True),                 \n",
    "                     StructField('Station Area', StringType(), True),       \n",
    "                     StructField('Box', StringType(), True),       \n",
    "                     StructField('Original Priority', StringType(), True),       \n",
    "                     StructField('Priority', StringType(), True),       \n",
    "                     StructField('Final Priority', IntegerType(), True),       \n",
    "                     StructField('ALS Unit', BooleanType(), True),       \n",
    "                     StructField('Call Type Group', StringType(), True),\n",
    "                     StructField('Number of Alarms', IntegerType(), True),\n",
    "                     StructField('Unit Type', StringType(), True),\n",
    "                     StructField('Unit sequence in call dispatch', IntegerType(), True),\n",
    "                     StructField('Fire Prevention District', StringType(), True),\n",
    "                     StructField('Supervisor District', StringType(), True),\n",
    "                     StructField('Neighborhood District', StringType(), True),\n",
    "                     StructField('Location', StringType(), True),\n",
    "                     StructField('RowID', StringType(), True)])\n",
    "\n",
    "# read the file using format CSV\n",
    "sf_fire_file = \"Fire_Department_Calls_for_Service.csv\"\n",
    "fire_df =spark.read.csv(sf_fire_file, header=True, mode=\"DROPMALFORMED\", schema=fireschema)\n",
    "CallType_df=(fire_df.select(\"Call Type\")).groupBy(\"Call Type\").count().sort('count',ascending=False)\n",
    "CallType_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5225735"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|Call Type                                   |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Lightning Strike (Investigation)            |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Train / Rail Fire                           |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "+--------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many different types of calls were made to the Fire Department?\n",
    "fire_df.select('Call Type').distinct().show(20,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|        Call Type|  count|\n",
      "+-----------------+-------+\n",
      "| Medical Incident|3411696|\n",
      "|   Structure Fire| 659644|\n",
      "|           Alarms| 565194|\n",
      "|Traffic Collision| 215006|\n",
      "|            Other|  82489|\n",
      "+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many incidents of each call type were there?\n",
    "CallType_df=(fire_df.select(\"Call Type\")).groupBy(\"Call Type\").count().sort('count',ascending=False)\n",
    "CallType_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|           Call Type|  count|\n",
      "+--------------------+-------+\n",
      "|    Medical Incident|3411696|\n",
      "|      Structure Fire| 659644|\n",
      "|              Alarms| 565194|\n",
      "|   Traffic Collision| 215006|\n",
      "|               Other|  82489|\n",
      "|Citizen Assist / ...|  78089|\n",
      "|        Outside Fire|  62767|\n",
      "|        Water Rescue|  25482|\n",
      "|        Vehicle Fire|  24510|\n",
      "|Gas Leak (Natural...|  20990|\n",
      "|   Electrical Hazard|  15536|\n",
      "|Elevator / Escala...|  14126|\n",
      "|Odor (Strange / U...|  12811|\n",
      "|Smoke Investigati...|  11646|\n",
      "|          Fuel Spill|   5995|\n",
      "|              HazMat|   4113|\n",
      "|Industrial Accidents|   2967|\n",
      "|           Explosion|   2747|\n",
      "|  Aircraft Emergency|   1511|\n",
      "|Train / Rail Inci...|   1389|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_df.select('Call Type').groupBy('Call Type').count().sort(\"count\", ascending=False)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "oldColumns = fire_df.schema.names\n",
    "newColumns = ['CallNumber',\n",
    " 'UnitID',\n",
    " 'IncidentNumber',\n",
    " 'CallType',\n",
    " 'CallDate',\n",
    " 'WatchDate',\n",
    " 'ReceivedDtTm',\n",
    " 'EntryDtTm',\n",
    " 'DispatchDtTm',\n",
    " 'ResponseDtTm',\n",
    " 'OnSceneDtTm',\n",
    " 'TransportDtTm',\n",
    " 'HospitalDtTm',\n",
    " 'CallFinalDisposition',\n",
    " 'AvailableDtTm',\n",
    " 'Address',\n",
    " 'City',\n",
    " 'ZipcodeofIncident',\n",
    " 'Battalion',\n",
    " 'StationArea',\n",
    " 'Box',\n",
    " 'OriginalPriority',\n",
    " 'Priority',\n",
    " 'FinalPriority',\n",
    " 'ALSUnit',\n",
    " 'CallTypeGroup',\n",
    " 'NumberofAlarms',\n",
    " 'UnitType',\n",
    " 'Unitsequenceincalldispatch',\n",
    " 'FirePreventionDistrict',\n",
    " 'SupervisorDistrict',\n",
    " 'NeighborhoodDistrict',\n",
    " 'Location',\n",
    " 'RowID'            \n",
    "]\n",
    "\n",
    "df = reduce(lambda data, idx: data.withColumnRenamed(oldColumns[idx], newColumns[idx]), range(len(oldColumns)), fire_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CallNumber',\n",
       " 'UnitID',\n",
       " 'IncidentNumber',\n",
       " 'CallType',\n",
       " 'CallDate',\n",
       " 'WatchDate',\n",
       " 'ReceivedDtTm',\n",
       " 'EntryDtTm',\n",
       " 'DispatchDtTm',\n",
       " 'ResponseDtTm',\n",
       " 'OnSceneDtTm',\n",
       " 'TransportDtTm',\n",
       " 'HospitalDtTm',\n",
       " 'CallFinalDisposition',\n",
       " 'AvailableDtTm',\n",
       " 'Address',\n",
       " 'City',\n",
       " 'ZipcodeofIncident',\n",
       " 'Battalion',\n",
       " 'StationArea',\n",
       " 'Box',\n",
       " 'OriginalPriority',\n",
       " 'Priority',\n",
       " 'FinalPriority',\n",
       " 'ALSUnit',\n",
       " 'CallTypeGroup',\n",
       " 'NumberofAlarms',\n",
       " 'UnitType',\n",
       " 'Unitsequenceincalldispatch',\n",
       " 'FirePreventionDistrict',\n",
       " 'SupervisorDistrict',\n",
       " 'NeighborhoodDistrict',\n",
       " 'Location',\n",
       " 'RowID']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_pattern1 = 'MM/dd/yyyy'\n",
    "to_pattern1 = 'yyyy-MM-dd'\n",
    "\n",
    "from_pattern2 = 'MM/dd/yyyy hh:mm:ss aa'\n",
    "to_pattern2 = 'MM/dd/yyyy hh:mm:ss aa'\n",
    "\n",
    "df_ts = df.withColumn('CallDateTS', unix_timestamp(df.CallDate, from_pattern1).cast(\"timestamp\"))\\\n",
    ".withColumn(\"ReceivedDtTmTS\", unix_timestamp(df.ReceivedDtTm, from_pattern2).cast(\"timestamp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = df.withColumn('Timestamp',from_unixtime(\n",
    "    unix_timestamp(df.ReceivedDtTm, \"yyyy-MM-dd'T'hh:mm:ss aa\"), \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Timestamp|\n",
      "+---------+\n",
      "|     null|\n",
      "|     null|\n",
      "+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts.select('Timestamp').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "df = sc.parallelize([Row(visit_dts='5/1/2018 3:48:14 PM')]).toDF()\n",
    "import pyspark.sql.functions as f\n",
    "web = df.withColumn(\"web_datetime\", f.from_unixtime(f.unix_timestamp(\"visit_dts\",'MM/dd/yyyy hh:mm:ss aa'),'MM/dd/yyyy HH:mm:ss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|          visit_dts|web_datetime|\n",
      "+-------------------+------------+\n",
      "|5/1/2018 3:48:14 PM|        null|\n",
      "+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "web.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+\n",
      "|         CallDateTs|ReceivedDtTmTS|\n",
      "+-------------------+--------------+\n",
      "|2019-07-25 00:00:00|          null|\n",
      "|2019-07-25 00:00:00|          null|\n",
      "+-------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_ts.select(\"CallDateTs\", \"ReceivedDtTmTS\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------+\n",
      "|         CallType|  count|\n",
      "+-----------------+-------+\n",
      "| Medical Incident|3411696|\n",
      "|   Structure Fire| 659644|\n",
      "|           Alarms| 565194|\n",
      "|Traffic Collision| 215006|\n",
      "|            Other|  82489|\n",
      "+-----------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "CallType_df2=(df.select(\"CallType\")).groupBy(\"CallType\").count().sort('count',ascending=False)\n",
    "CallType_df2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "few_fire_df = (df.select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \n",
    "           .where(df.CallType != \"Medical Incident\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_df=(few_fire_df.select(\"CallType\")).groupBy(\"CallType\").count().sort('count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|            CallType| count|\n",
      "+--------------------+------+\n",
      "|      Structure Fire|659644|\n",
      "|              Alarms|565194|\n",
      "|   Traffic Collision|215006|\n",
      "|               Other| 82489|\n",
      "|Citizen Assist / ...| 78089|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "call_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            CallType|\n",
      "+--------------------+\n",
      "|Elevator / Escala...|\n",
      "|         Marine Fire|\n",
      "|  Aircraft Emergency|\n",
      "|Confined Space / ...|\n",
      "|      Administrative|\n",
      "|              Alarms|\n",
      "|Odor (Strange / U...|\n",
      "|Lightning Strike ...|\n",
      "|Citizen Assist / ...|\n",
      "|              HazMat|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"CallType\").where(df.CallType != \"null\").distinct().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|        CallType|\n",
      "+----------------+\n",
      "|  Structure Fire|\n",
      "|  Structure Fire|\n",
      "|  Structure Fire|\n",
      "|  Structure Fire|\n",
      "|  Structure Fire|\n",
      "|  Structure Fire|\n",
      "|Medical Incident|\n",
      "|Medical Incident|\n",
      "|          Alarms|\n",
      "|          Alarms|\n",
      "+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"CallType\").where(df.CallType != \"null\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Column name\n",
    "df2 = df.withColumnRenamed(\"CallNumber\", \"NumberOfCalls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NumberOfCalls'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|  CallDate|\n",
      "+----------+\n",
      "|12/26/2004|\n",
      "|06/26/2005|\n",
      "|06/14/2010|\n",
      "|03/02/2011|\n",
      "|01/03/2012|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"CallDate\").where(df.CallDate != \"null\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+\n",
      "|ReceivedDtTm          |ResponseDtTm          |\n",
      "+----------------------+----------------------+\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:21:12 PM|\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:19:14 PM|\n",
      "+----------------------+----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ReceivedDtTm\",\"ResponseDtTm\" ).where(df.ResponseDtTm != \"null\").show(2,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------+----------------------+\n",
      "|IncidentDate       |OnWatchDate        |AvailableDtTS|AvailableDtTm         |\n",
      "+-------------------+-------------------+-------------+----------------------+\n",
      "|2019-04-25 00:00:00|2019-04-25 00:00:00|null         |04/25/2019 03:28:56 PM|\n",
      "|2019-04-25 00:00:00|2019-04-25 00:00:00|null         |04/25/2019 06:08:58 PM|\n",
      "|2018-02-01 00:00:00|2018-02-01 00:00:00|null         |02/01/2018 12:38:05 PM|\n",
      "+-------------------+-------------------+-------------+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    " \n",
    "fire_ts_df = (df.withColumn(\"IncidentDate\", to_timestamp(df.CallDate, \"MM/dd/yyyy\"))\n",
    ".withColumn(\"OnWatchDate\", to_timestamp(df.WatchDate, \"MM/dd/yyyy\"))\n",
    ".withColumn(\"AvailableDtTS\", to_timestamp(df.AvailableDtTm, \"MM/dd/yyyy hh:mm:ss aa\")))\n",
    "\n",
    "fire_ts_df.select(\"IncidentDate\", \"OnWatchDate\", \"AvailableDtTS\", \"AvailableDtTm\").distinct().show(3, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|year(IncidentDate)|\n",
      "+------------------+\n",
      "|              2000|\n",
      "|              2001|\n",
      "|              2002|\n",
      "|              2003|\n",
      "|              2004|\n",
      "|              2005|\n",
      "|              2006|\n",
      "|              2007|\n",
      "|              2008|\n",
      "|              2009|\n",
      "|              2010|\n",
      "|              2011|\n",
      "|              2012|\n",
      "|              2013|\n",
      "|              2014|\n",
      "|              2015|\n",
      "|              2016|\n",
      "|              2017|\n",
      "|              2018|\n",
      "|              2019|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "fire_ts_df.select(year('IncidentDate')).distinct().orderBy(year('IncidentDate')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+-------+\n",
      "|CallType                       |count  |\n",
      "+-------------------------------+-------+\n",
      "|Medical Incident               |3411696|\n",
      "|Structure Fire                 |659644 |\n",
      "|Alarms                         |565194 |\n",
      "|Traffic Collision              |215006 |\n",
      "|Other                          |82489  |\n",
      "|Citizen Assist / Service Call  |78089  |\n",
      "|Outside Fire                   |62767  |\n",
      "|Water Rescue                   |25482  |\n",
      "|Vehicle Fire                   |24510  |\n",
      "|Gas Leak (Natural and LP Gases)|20990  |\n",
      "+-------------------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What were the common types of fire calls?\n",
    "fire_ts_df.select(\"CallType\").where(col(\"CallType\").isNotNull()).groupBy(\"CallType\").count().orderBy(\n",
    "    \"count\", ascending=False).show(10, truncate=False)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+----------------------+\n",
      "|ReceivedDtTm          |ResponseDtTm          |\n",
      "+----------------------+----------------------+\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:21:12 PM|\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:19:14 PM|\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:19:29 PM|\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:20:30 PM|\n",
      "|07/25/2019 07:16:45 PM|07/25/2019 07:19:32 PM|\n",
      "+----------------------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.select('ReceivedDtTm', 'ResponseDtTm').show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to fix the issue with \"null\" timestamp\n",
    "\n",
    "from pyspark.sql import Row\n",
    "df = sc.parallelize([Row(visit_dts='5/1/2018 3:48:14 PM')]).toDF()\n",
    "import pyspark.sql.functions as f\n",
    "web = df.withColumn(\"web_datetime\", \n",
    "                    f.from_unixtime(f.unix_timestamp(\"visit_dts\",'MM/dd/yyyy hh:mm:ss aa'),'MM/dd/yyyy HH:mm:ss'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------+\n",
      "|          visit_dts|web_datetime|\n",
      "+-------------------+------------+\n",
      "|5/1/2018 3:48:14 PM|        null|\n",
      "+-------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "web.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|sum(NumberOfAlarms)|\n",
      "+-------------------+\n",
      "|            5253779|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fire_ts_df.select(sum(\"NumberOfAlarms\")).show()         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Train / Rail Fire                           |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What were all the different types of fire calls in 2018?\n",
    "calltype_df_2018=(fire_ts_df.select(\"CallType\").where(year(fire_ts_df.IncidentDate) == 2018)).distinct()\n",
    "calltype_df_2018.show(calltype_df_2018.count(),False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Train / Rail Fire                           |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What were all the different types of fire calls in 2019?\n",
    "calltype_df_2019=(fire_ts_df.select(\"CallType\").where(year(fire_ts_df.IncidentDate) == 2019)).distinct()\n",
    "calltype_df_2019.show(calltype_df_2019.count(),False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Month|count|\n",
      "+-----+-----+\n",
      "|   10|29209|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q1: What months within the year 2019 saw for the highest number of fire calls?\n",
    "\n",
    "# Adding a new column \"Month\" to the new datafram fire_ts_m_df\n",
    "fire_ts_m_df = fire_ts_df.withColumn(\"Month\", month(fire_ts_df.IncidentDate))\n",
    "\n",
    "# Show the month in the year 2019 saw the highest nuber of fire calls\n",
    "(fire_ts_m_df.select(\"Month\",\"CallNumber\").where(year(fire_ts_df.IncidentDate) == 2019)\n",
    "   .groupby(\"Month\").count().orderBy(\"count\",ascending=False )).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Month|count|\n",
      "+-----+-----+\n",
      "|    1|27027|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the month in the year 2018 saw the highest nuber of fire calls\n",
    "(fire_ts_m_df.select(\"Month\",\"CallNumber\").where(year(fire_ts_df.IncidentDate) == 2018)\n",
    "   .groupby(\"Month\").count().orderBy(\"count\",ascending=False )).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Month|count|\n",
      "+-----+-----+\n",
      "|    1|28026|\n",
      "+-----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the month in the year 2017 saw the highest nuber of fire calls\n",
    "(fire_ts_m_df.select(\"Month\",\"CallNumber\").where(year(fire_ts_df.IncidentDate) == 2017)\n",
    "   .groupby(\"Month\").count().orderBy(\"count\",ascending=False )).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|NeighborhoodDistrict|count|\n",
      "+--------------------+-----+\n",
      "|Tenderloin          |45852|\n",
      "+--------------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q2 Which neighborhood in SF generated the most fire calls in 2019?\n",
    "\n",
    "(fire_ts_df.select(\"NeighborhoodDistrict\").where(year(fire_ts_df.IncidentDate) == 2019)).groupby(\n",
    "    \"NeighborhoodDistrict\").count().orderBy(\"count\",ascending=False ).show(1,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|NeighborhoodDistrict          |count|\n",
      "+------------------------------+-----+\n",
      "|Tenderloin                    |35897|\n",
      "|South of Market               |28645|\n",
      "|Mission                       |25205|\n",
      "|Financial District/South Beach|16343|\n",
      "|Bayview Hunters Point         |13284|\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"NeighborhoodDistrict\").where(year(fire_ts_df.IncidentDate) == 2011)).groupby(\n",
    "    \"NeighborhoodDistrict\").count().orderBy(\"count\",ascending=False ).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|NeighborhoodDistrict          |count|\n",
      "+------------------------------+-----+\n",
      "|Tenderloin                    |20063|\n",
      "|Mission                       |14563|\n",
      "|South of Market               |13830|\n",
      "|Financial District/South Beach|12880|\n",
      "|Bayview Hunters Point         |10175|\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"NeighborhoodDistrict\").where(year(fire_ts_df.IncidentDate) == 2000)).groupby(\n",
    "    \"NeighborhoodDistrict\").count().orderBy(\"count\",ascending=False ).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3 Which neighborhoods in SF had the worst response time to fire calls in 2018?\n",
    "# need to fix the null issue of timestamp to answer this question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Week|count|\n",
      "+----+-----+\n",
      "|  43| 7311|\n",
      "+----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q4 Which week in the year in 2019 had the most fire calls?\n",
    "\n",
    "# Adding a new column \"Week\" to the new datafram fire_ts_m_w_df\n",
    "fire_ts_m_w_df = fire_ts_m_df.withColumn(\"Week\", weekofyear(fire_ts_m_df.IncidentDate))\n",
    "\n",
    "(fire_ts_m_w_df.select(\"Week\").where(year(fire_ts_m_w_df.IncidentDate) == 2019)\n",
    "   .groupby(\"Week\").count().orderBy(\"count\",ascending=False )).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Week|count|\n",
      "+----+-----+\n",
      "|  24| 4757|\n",
      "+----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_m_w_df.select(\"Week\").where(year(fire_ts_m_w_df.IncidentDate) == 2000)\n",
    "   .groupby(\"Week\").count().orderBy(\"count\",ascending=False )).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|Week|count|\n",
      "+----+-----+\n",
      "|   1| 7545|\n",
      "+----+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_m_w_df.select(\"Week\").where(year(fire_ts_m_w_df.IncidentDate) == 2018)\n",
    "   .groupby(\"Week\").count().orderBy(\"count\",ascending=False )).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------+-----+\n",
      "|NeighborhoodDistrict |ZipcodeofIncident|count|\n",
      "+---------------------+-----------------+-----+\n",
      "|Tenderloin           |94102            |34027|\n",
      "|South of Market      |94103            |29156|\n",
      "|Mission              |94110            |17538|\n",
      "|Bayview Hunters Point|94124            |16013|\n",
      "|Mission              |94103            |11168|\n",
      "+---------------------+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Q5 Is there a correlation between neighborhood, zip code, and fire calls?\n",
    "\n",
    "(fire_ts_df.select(\"NeighborhoodDistrict\",\"ZipcodeofIncident\").where(year(fire_ts_df.IncidentDate) == 2019)).groupby(\n",
    "    \"NeighborhoodDistrict\", \"ZipcodeofIncident\").count().orderBy(\"count\",ascending=False ).show(5,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-----+\n",
      "|NeighborhoodDistrict          |count|\n",
      "+------------------------------+-----+\n",
      "|Tenderloin                    |45852|\n",
      "|South of Market               |35007|\n",
      "|Mission                       |28763|\n",
      "|Financial District/South Beach|22652|\n",
      "|Bayview Hunters Point         |17008|\n",
      "+------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"NeighborhoodDistrict\").where(year(fire_ts_df.IncidentDate) == 2019)).groupby(\n",
    "    \"NeighborhoodDistrict\").count().orderBy(\"count\",ascending=False ).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|ZipcodeofIncident|count|\n",
      "+-----------------+-----+\n",
      "|94103            |43506|\n",
      "|94102            |42591|\n",
      "|94109            |28257|\n",
      "|94110            |24592|\n",
      "|94124            |16444|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"ZipcodeofIncident\").where(year(fire_ts_df.IncidentDate) == 2019)).groupby(\n",
    "    \"ZipcodeofIncident\").count().orderBy(\"count\",ascending=False ).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|ZipcodeofIncident|NeighborhoodDistrict|\n",
      "+-----------------+--------------------+\n",
      "|            94102|          Tenderloin|\n",
      "|            94109|          Tenderloin|\n",
      "|            94103|          Tenderloin|\n",
      "+-----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"ZipcodeofIncident\",\"NeighborhoodDistrict\").where(\n",
    "    fire_ts_df.NeighborhoodDistrict ==\"Tenderloin\")).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|NeighborhoodDistrict|ZipcodeofIncident|\n",
      "+--------------------+-----------------+\n",
      "|    Western Addition|            94102|\n",
      "|          Tenderloin|            94102|\n",
      "|            Nob Hill|            94102|\n",
      "|             Mission|            94102|\n",
      "|     South of Market|            94102|\n",
      "|Financial Distric...|            94102|\n",
      "|        Hayes Valley|            94102|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(fire_ts_df.select(\"NeighborhoodDistrict\",\"ZipcodeofIncident\").where(\n",
    "    fire_ts_df.ZipcodeofIncident == 94102)).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o1886.csv.\n: ExitCodeException exitCode=-1073741515: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:901)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:547)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:586)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:586)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:705)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:354)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:163)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:168)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:123)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:173)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:211)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:208)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:828)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:828)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:818)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-150-3c3514c6e279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msqlDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM fire_Table\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0msqlDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fire_table.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0msqlDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Spark\\spark-3.0.0-preview2-bin-hadoop3.2\\python\\pyspark\\sql\\readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[1;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[0;32m    969\u001b[0m                        \u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcharToEscapeQuoteEscaping\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m                        encoding=encoding, emptyValue=emptyValue, lineSep=lineSep)\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msince\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Spark\\spark-3.0.0-preview2-bin-hadoop3.2\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1284\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1286\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Spark\\spark-3.0.0-preview2-bin-hadoop3.2\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Spark\\spark-3.0.0-preview2-bin-hadoop3.2\\python\\lib\\py4j-0.10.8.1-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o1886.csv.\n: ExitCodeException exitCode=-1073741515: \r\n\tat org.apache.hadoop.util.Shell.runCommand(Shell.java:1008)\r\n\tat org.apache.hadoop.util.Shell.run(Shell.java:901)\r\n\tat org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1213)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1307)\r\n\tat org.apache.hadoop.util.Shell.execCommand(Shell.java:1289)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:865)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:547)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:587)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:586)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:586)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:559)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:705)\r\n\tat org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter.setupJob(FileOutputCommitter.java:354)\r\n\tat org.apache.spark.internal.io.HadoopMapReduceCommitProtocol.setupJob(HadoopMapReduceCommitProtocol.scala:163)\r\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:168)\r\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\r\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:123)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:173)\r\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:211)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:208)\r\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:169)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:110)\r\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:109)\r\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:828)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$4(SQLExecution.scala:100)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)\r\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:87)\r\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:828)\r\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:309)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:293)\r\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:236)\r\n\tat org.apache.spark.sql.DataFrameWriter.csv(DataFrameWriter.scala:818)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n"
     ]
    }
   ],
   "source": [
    "fire_ts_m_w_df.createOrReplaceTempView(\"fire_table\")\n",
    "\n",
    "sqlDF = spark.sql(\"SELECT * FROM fire_Table\")\n",
    "sqlDF.coalesce(1).write.csv(\"fire_table.csv\")\n",
    "sqlDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
